{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FfM9kuLgABC",
        "outputId": "012b6036-0e0e-4c67-d1d3-3268b6d63b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/MyDrive/NLP assessment/test_oJQbWVk.csv\"\n",
        "df = pd.read_csv(path)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHXxfHWIgXIv",
        "outputId": "863dd430-6be6-41de-b71e-881d08f64f04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id                                              tweet\n",
            "0     7921  I hate the new #iphone upgrade. Won't let me d...\n",
            "1     7922  currently shitting my fucking pants. #apple #i...\n",
            "2     7923  I'd like to puts some CD-ROMS on my iPad, is t...\n",
            "3     7924  My ipod is officially dead. I lost all my pict...\n",
            "4     7925  Been fighting iTunes all night! I only want th...\n",
            "...    ...                                                ...\n",
            "1948  9869  #SamsungGalaxyNote7 Explodes, Burns 6-Year-Old...\n",
            "1949  9870  Now Available - Hoodie. Check it out here - ht...\n",
            "1950  9871  There goes a crack right across the screen. If...\n",
            "1951  9872  @codeofinterest as i said #Adobe big time we m...\n",
            "1952  9873  Finally I got it .. thanx my father .. #Samsun...\n",
            "\n",
            "[1953 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path1=\"/content/drive/MyDrive/NLP assessment/train_2kmZucJ.csv\"\n",
        "df=pd.read_csv(path1)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pU_yWF7hY3n",
        "outputId": "55220ad9-195a-4a46-8b3e-d5ed613d2bc9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id  label                                              tweet\n",
            "0        1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
            "1        2      0  Finally a transparant silicon case ^^ Thanks t...\n",
            "2        3      0  We love this! Would you go? #talk #makememorie...\n",
            "3        4      0  I'm wired I know I'm George I was made that wa...\n",
            "4        5      1  What amazing service! Apple won't even talk to...\n",
            "...    ...    ...                                                ...\n",
            "7915  7916      0  Live out loud #lol #liveoutloud #selfie #smile...\n",
            "7916  7917      0  We would like to wish you an amazing day! Make...\n",
            "7917  7918      0  Helping my lovely 90 year old neighbor with he...\n",
            "7918  7919      0  Finally got my #smart #pocket #wifi stay conne...\n",
            "7919  7920      0  Apple Barcelona!!! #Apple #Store #BCN #Barcelo...\n",
            "\n",
            "[7920 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# -------------------------------\n",
        "# Step 1: Load the datasets\n",
        "# -------------------------------\n",
        "path=\"/content/drive/MyDrive/NLP assessment/test_oJQbWVk.csv\"\n",
        "test_df = pd.read_csv(path)\n",
        "path1=\"/content/drive/MyDrive/NLP assessment/train_2kmZucJ.csv\"\n",
        "train_df = pd.read_csv(path1)\n",
        "path2=\"/content/drive/MyDrive/NLP assessment/sample_submission_LnhVWA4.csv\"\n",
        "sample_submission_df = pd.read_csv(path2)\n",
        "\n",
        "# -------------------------------\n",
        "# Step 2: Clean the tweets\n",
        "# -------------------------------\n",
        "def clean_tweet(tweet):\n",
        "    tweet = tweet.lower()\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet)\n",
        "    tweet = re.sub(r\"@\\w+|#\\w+\", '', tweet)\n",
        "    tweet = re.sub(r\"[^a-z0-9\\s]\", '', tweet)\n",
        "    return tweet.strip()\n",
        "\n",
        "train_df[\"clean_tweet\"] = train_df[\"tweet\"].apply(clean_tweet)\n",
        "test_df[\"clean_tweet\"] = test_df[\"tweet\"].apply(clean_tweet)\n",
        "\n",
        "# -------------------------------\n",
        "# Step 3: TF-IDF Feature Extraction\n",
        "# -------------------------------\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "X = vectorizer.fit_transform(train_df[\"clean_tweet\"])\n",
        "y = train_df[\"label\"]\n",
        "\n",
        "# Optional: Split for validation (local evaluation only)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# -------------------------------\n",
        "# Step 4: Train Logistic Regression\n",
        "# -------------------------------\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on validation set\n",
        "y_val_pred = model.predict(X_val)\n",
        "print(\"ðŸ“Š Validation Classification Report:\")\n",
        "print(classification_report(y_val, y_val_pred, digits=4))\n",
        "\n",
        "# -------------------------------\n",
        "# Step 5: Predict on Test Data\n",
        "# -------------------------------\n",
        "X_test = vectorizer.transform(test_df[\"clean_tweet\"])\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# -------------------------------\n",
        "# Step 6: Create Submission File\n",
        "# -------------------------------\n",
        "submission_df = sample_submission_df.copy()\n",
        "submission_df[\"label\"] = test_predictions\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"\\nSubmission file 'submission.csv' has been saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7xGXiGkgiZd",
        "outputId": "4038d7e5-6373-4dcd-fe5b-8282726da624"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9410    0.8651    0.9015      1179\n",
            "           1     0.6820    0.8420    0.7536       405\n",
            "\n",
            "    accuracy                         0.8592      1584\n",
            "   macro avg     0.8115    0.8536    0.8275      1584\n",
            "weighted avg     0.8747    0.8592    0.8637      1584\n",
            "\n",
            "\n",
            "Submission file 'submission.csv' has been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"submission.csv\")"
      ],
      "metadata": {
        "id": "gv8GOrJmj9Mc",
        "outputId": "5ae42ac7-e59a-4921-b836-240312a6e69a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_682ba13b-cea3-4216-9db5-cd2f16453a7f\", \"submission.csv\", 13680)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}